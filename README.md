# ğŸŒ Web Data Extraction and Summarization Tool (WDEST)

### ğŸš€ Overview

**Web Data Extraction and Summarization Tool (WDEST)** is an AI-powered application that extracts meaningful content from web pages and automatically generates concise summaries using a Large Language Model (LLM) hosted on **Groq**.  

It provides a simple, interactive **Streamlit** interface where users can input a URL, extract the page data, and instantly view a summarized version of its content.  

This project aims to simplify research and save time for students, journalists, and professionals who deal with large amounts of online information.

---

## ğŸ§  Project Motivation

Thereâ€™s too much unstructured information on the internet. Finding relevant data quickly and understanding it takes time.  
Our tool automates this process â€” it **scrapes**, **processes**, and **summarizes** web data into an easy-to-digest summary.

---

## ğŸ—ï¸ System Architecture

The system consists of three main modules:

1. **Web Scraper** â€“ Extracts readable content from the given URL using `Selenium` and `BeautifulSoup`.
2. **Summarizer** â€“ Sends the extracted content to an **OpenAI OSS model hosted on Groq** for summarization.
3. **User Interface (UI)** â€“ Built with `Streamlit` to provide a clean, simple, and interactive experience.

---

## âœ¨ Features

- ğŸ” **Automatic Web Content Extraction**  
  Extracts readable text from a given web page.
  
- ğŸ§© **Smart AI Summarization**  
  Uses Groq-hosted LLMs (OpenAI OSS models) to summarize content.

- ğŸ–¥ï¸ **Interactive Web Interface**  
  Simple and clean interface using Streamlit.

- ğŸ”’ **Secure Configuration**  
  Environment variables managed via `.env` for API keys.

---

## âš™ï¸ Tech Stack

| Component | Technology Used |
|------------|----------------|
| **Frontend / UI** | Streamlit, HTML, CSS, JS |
| **Backend Logic** | Python |
| **Libraries** | BeautifulSoup4, Selenium, LXML, HTML5lib |
| **Summarization** | LLaMA / OpenAI OSS model via Groq API |
| **Configuration** | python-dotenv |
| **Deployment** | Docker / Virtual Environment |

---
## ğŸ§© Project Structure
â”œâ”€â”€ app.py # Main Streamlit Application
â”œâ”€â”€ scraper.py # Handles web scraping logic
â”œâ”€â”€ summarizer.py # Handles summarization using Groq API
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env.example # Example environment file
â”œâ”€â”€ Dockerfile # Docker image setup
â”œâ”€â”€ docker-compose.yml # Docker service configuration
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ assets/ # (Optional) UI assets like logos or icons
---

## ğŸª„ Installation & Setup

You can set up the project in **two ways**:

---

### ğŸ§± Option 1: Using Virtual Environment

#### 1. Clone the Repository
```bash
git clone https://github.com/<your-username>/web-data-extraction-summarization.git
cd web-data-extraction-summarization


